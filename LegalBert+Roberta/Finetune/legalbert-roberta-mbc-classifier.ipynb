{"cells":[{"cell_type":"markdown","metadata":{},"source":["## Installing necessary packages"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-02-27T09:23:21.224947Z","iopub.status.busy":"2023-02-27T09:23:21.224512Z","iopub.status.idle":"2023-02-27T09:23:31.969054Z","shell.execute_reply":"2023-02-27T09:23:31.967752Z","shell.execute_reply.started":"2023-02-27T09:23:21.224908Z"},"trusted":true},"outputs":[],"source":["!pip install transformers --q"]},{"cell_type":"markdown","metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5"},"source":["## Importing necessary packages"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-02-27T09:23:31.972512Z","iopub.status.busy":"2023-02-27T09:23:31.971863Z","iopub.status.idle":"2023-02-27T09:23:40.973060Z","shell.execute_reply":"2023-02-27T09:23:40.971962Z","shell.execute_reply.started":"2023-02-27T09:23:31.972462Z"},"trusted":true},"outputs":[],"source":["import pandas as pd\n","import numpy as np\n","from numpy import zeros\n","\n","from tqdm import tqdm\n","\n","import json\n","import torch\n","\n","from transformers import AutoModel, AutoTokenizer\n","from sklearn.preprocessing import LabelEncoder\n","from sklearn.metrics import accuracy_score, f1_score\n","\n","\n","import torch as th\n","import torch.utils.data as Data\n","from torch.optim import lr_scheduler\n","import torch.nn.functional as F\n","\n","import matplotlib.pyplot as plt\n","%matplotlib inline"]},{"cell_type":"markdown","metadata":{},"source":["## Parameters"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-02-27T09:23:40.976086Z","iopub.status.busy":"2023-02-27T09:23:40.974925Z","iopub.status.idle":"2023-02-27T09:23:40.982367Z","shell.execute_reply":"2023-02-27T09:23:40.980833Z","shell.execute_reply.started":"2023-02-27T09:23:40.976041Z"},"trusted":true},"outputs":[],"source":["sequence_length = 256\n","embedding_dim = 256\n","batch_size = 16\n","epochs = 20\n","model_name = 'nlpaueb/legal-bert-base-uncased'\n","output_type = 'mean_pooled' # by default CLS"]},{"cell_type":"markdown","metadata":{},"source":["## Dataset Loader"]},{"cell_type":"markdown","metadata":{},"source":["#### Training dataset"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-02-27T09:23:40.985904Z","iopub.status.busy":"2023-02-27T09:23:40.985433Z","iopub.status.idle":"2023-02-27T09:23:41.184834Z","shell.execute_reply":"2023-02-27T09:23:41.183846Z","shell.execute_reply.started":"2023-02-27T09:23:40.985847Z"},"trusted":true},"outputs":[],"source":["train_df = pd.read_csv('../../data/model_data/train_df.csv')\n","print(\"# Size: \", train_df.shape)\n","train_df.head()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-02-27T09:23:41.186951Z","iopub.status.busy":"2023-02-27T09:23:41.186496Z","iopub.status.idle":"2023-02-27T09:23:41.200507Z","shell.execute_reply":"2023-02-27T09:23:41.198970Z","shell.execute_reply.started":"2023-02-27T09:23:41.186910Z"},"trusted":true},"outputs":[],"source":["print(\"#Nan in sents: \", train_df.sentence.isnull().values.sum())\n","print(\"#Nan in labels: \", train_df.label.isnull().values.sum())"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-02-27T09:23:41.202109Z","iopub.status.busy":"2023-02-27T09:23:41.201815Z","iopub.status.idle":"2023-02-27T09:23:41.214684Z","shell.execute_reply":"2023-02-27T09:23:41.213499Z","shell.execute_reply.started":"2023-02-27T09:23:41.202077Z"},"trusted":true},"outputs":[],"source":["train_df.label.value_counts()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{},"source":["#### Validation dataset"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-02-27T09:23:41.217088Z","iopub.status.busy":"2023-02-27T09:23:41.216657Z","iopub.status.idle":"2023-02-27T09:23:41.253968Z","shell.execute_reply":"2023-02-27T09:23:41.252943Z","shell.execute_reply.started":"2023-02-27T09:23:41.216992Z"},"trusted":true},"outputs":[],"source":["dev_df = pd.read_csv('../../data/model_data/dev_df.csv')\n","print(\"# Size: \", dev_df.shape)\n","dev_df.head()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-02-27T09:23:41.255830Z","iopub.status.busy":"2023-02-27T09:23:41.255494Z","iopub.status.idle":"2023-02-27T09:23:41.263318Z","shell.execute_reply":"2023-02-27T09:23:41.262139Z","shell.execute_reply.started":"2023-02-27T09:23:41.255795Z"},"trusted":true},"outputs":[],"source":["print(\"#Nan in sents: \", dev_df.sentence.isnull().values.sum())\n","print(\"#Nan in labels: \", dev_df.label.isnull().values.sum())"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-02-27T09:23:41.265957Z","iopub.status.busy":"2023-02-27T09:23:41.265088Z","iopub.status.idle":"2023-02-27T09:23:41.276869Z","shell.execute_reply":"2023-02-27T09:23:41.275552Z","shell.execute_reply.started":"2023-02-27T09:23:41.265918Z"},"trusted":true},"outputs":[],"source":["dev_df.label.value_counts()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{},"source":["#### Reading labels"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-02-27T09:23:41.282136Z","iopub.status.busy":"2023-02-27T09:23:41.281832Z","iopub.status.idle":"2023-02-27T09:23:41.302801Z","shell.execute_reply":"2023-02-27T09:23:41.301557Z","shell.execute_reply.started":"2023-02-27T09:23:41.282110Z"},"trusted":true},"outputs":[],"source":["le_encoder = LabelEncoder()\n","le_encoder.fit(list(train_df.label.values) + list(dev_df.label.values))\n","\n","label_names = le_encoder.classes_\n","print(label_names)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-02-27T09:23:41.305014Z","iopub.status.busy":"2023-02-27T09:23:41.304586Z","iopub.status.idle":"2023-02-27T09:23:41.324817Z","shell.execute_reply":"2023-02-27T09:23:41.323898Z","shell.execute_reply.started":"2023-02-27T09:23:41.304977Z"},"trusted":true},"outputs":[],"source":["ID_Label_Map = {}\n","with open('../../data/model_data/ID_Label_Map.json', 'r') as fp:\n","    ID_Label_Map = json.load(fp)\n","\n","Label_ID_Map = {}\n","with open('../../data/model_data/Label_ID_Map.json', 'r') as fp:\n","    Label_ID_Map = json.load(fp)\n","\n","print(list(Label_ID_Map.keys()))"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-02-27T09:23:41.327386Z","iopub.status.busy":"2023-02-27T09:23:41.327115Z","iopub.status.idle":"2023-02-27T09:23:41.353958Z","shell.execute_reply":"2023-02-27T09:23:41.352951Z","shell.execute_reply.started":"2023-02-27T09:23:41.327360Z"},"trusted":true},"outputs":[],"source":["train_labels = le_encoder.transform(list(train_df.label.values))\n","print(\"# Labels: \", len(train_labels))"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-02-27T09:23:41.355897Z","iopub.status.busy":"2023-02-27T09:23:41.355497Z","iopub.status.idle":"2023-02-27T09:23:41.363741Z","shell.execute_reply":"2023-02-27T09:23:41.362463Z","shell.execute_reply.started":"2023-02-27T09:23:41.355840Z"},"trusted":true},"outputs":[],"source":["dev_labels = le_encoder.transform(list(dev_df.label.values))\n","print(\"# Labels: \", len(dev_labels))"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-02-27T09:23:41.365966Z","iopub.status.busy":"2023-02-27T09:23:41.365406Z","iopub.status.idle":"2023-02-27T09:23:41.376222Z","shell.execute_reply":"2023-02-27T09:23:41.375241Z","shell.execute_reply.started":"2023-02-27T09:23:41.365929Z"},"trusted":true},"outputs":[],"source":["dev_sentences = list(dev_df.sentence.values)\n","dev_actual_labels = list(dev_df.label.values)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{},"source":["## Bert Model"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-02-27T09:23:41.378331Z","iopub.status.busy":"2023-02-27T09:23:41.377870Z","iopub.status.idle":"2023-02-27T09:23:41.391010Z","shell.execute_reply":"2023-02-27T09:23:41.389793Z","shell.execute_reply.started":"2023-02-27T09:23:41.378288Z"},"trusted":true},"outputs":[],"source":["class BertClassifier(th.nn.Module):\n","    def __init__(self, base_model = 'roberta-base', pretrained_model='roberta-base', nb_classes = 13, embedding_dim = 512):\n","        super(BertClassifier, self).__init__()\n","        self.nb_classes = nb_classes\n","        self.embedding_dim = embedding_dim\n","        \n","        self.tokenizer_1 = AutoTokenizer.from_pretrained(pretrained_model)\n","        self.tokenizer_2 = AutoTokenizer.from_pretrained(base_model)\n","        \n","        self.bert_model_1 = AutoModel.from_pretrained(pretrained_model)\n","        self.bert_model_2 = AutoModel.from_pretrained(base_model)\n","        \n","        self.feat_dim_1 = list(self.bert_model_1.modules())[-2].out_features\n","        self.classifier_1 = th.nn.Linear(self.feat_dim_1, self.embedding_dim)\n","        \n","        self.feat_dim_2 = list(self.bert_model_2.modules())[-2].out_features\n","        self.classifier_2 = th.nn.Linear(self.feat_dim_2, self.embedding_dim)\n","        \n","        self.fcs = th.nn.ModuleList([th.nn.Linear(2 * self.embedding_dim, 1) for _ in range(self.nb_classes)])\n","    \n","    def forward(self, input_ids = None, attention_mask = None, output_type = 'CLS'):\n","        \n","        input_ids_1 = input_ids[0]\n","        attention_mask_1 = attention_mask[0]\n","        bert_output = None\n","        if output_type=='mean_pooled':\n","            output = self.bert_model_1(input_ids_1, attention_mask=attention_mask_1).last_hidden_state\n","            ### Mean Pooling\n","            bert_output = output.sum(axis=1) / attention_mask.sum(axis=-1).unsqueeze(-1)\n","        else:\n","            bert_output = self.bert_model_1(input_ids_1, attention_mask=attention_mask_1)[0][:, 0]\n","        output_1 = torch.squeeze(self.classifier_1(bert_output))\n","        \n","\n","\n","        input_ids_2 = input_ids[1]\n","        attention_mask_2 = attention_mask[1]\n","        bert_output = None\n","        if output_type=='mean_pooled':\n","            output = self.bert_model_2(input_ids_2, attention_mask=attention_mask_2).last_hidden_state\n","            ### Mean Pooling\n","            bert_output = output.sum(axis=1) / attention_mask.sum(axis=-1).unsqueeze(-1)\n","        else:\n","            bert_output = self.bert_model_2(input_ids_2, attention_mask=attention_mask_2)[0][:, 0]\n","        output_2 = torch.squeeze(self.classifier_2(bert_output))\n","\n","\n","        \n","        last_hidden_states = th.cat((output_1.float(), output_2.float()), -1)\n","        logits = [th.sigmoid(fc(last_hidden_states)) for fc in self.fcs]\n","        \n","        return torch.cat(logits, dim=-1)"]},{"cell_type":"markdown","metadata":{},"source":["### Read testset"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-02-27T09:23:41.393228Z","iopub.status.busy":"2023-02-27T09:23:41.392800Z","iopub.status.idle":"2023-02-27T09:24:05.151433Z","shell.execute_reply":"2023-02-27T09:24:05.150346Z","shell.execute_reply.started":"2023-02-27T09:23:41.393193Z"},"trusted":true},"outputs":[],"source":["model = BertClassifier(pretrained_model = model_name, nb_classes=len(ID_Label_Map), embedding_dim = embedding_dim)\n","model.cuda()"]},{"cell_type":"markdown","metadata":{},"source":["#### Preparing the data loader for bert classifier"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-02-27T09:24:05.158230Z","iopub.status.busy":"2023-02-27T09:24:05.155935Z","iopub.status.idle":"2023-02-27T09:24:05.165677Z","shell.execute_reply":"2023-02-27T09:24:05.164532Z","shell.execute_reply.started":"2023-02-27T09:24:05.158189Z"},"trusted":true},"outputs":[],"source":["device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-02-27T09:24:05.170791Z","iopub.status.busy":"2023-02-27T09:24:05.170105Z","iopub.status.idle":"2023-02-27T09:24:05.185611Z","shell.execute_reply":"2023-02-27T09:24:05.184524Z","shell.execute_reply.started":"2023-02-27T09:24:05.170703Z"},"trusted":true},"outputs":[],"source":["def encode_input(text, tokenizer):\n","    tokenized_text = tokenizer(\n","        text,\n","        max_length = sequence_length,\n","        padding='max_length',\n","        truncation=True,\n","        return_tensors='pt'\n","    )\n","    return tokenized_text.input_ids, tokenized_text.attention_mask"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-02-27T09:24:05.187718Z","iopub.status.busy":"2023-02-27T09:24:05.187283Z","iopub.status.idle":"2023-02-27T09:24:05.198678Z","shell.execute_reply":"2023-02-27T09:24:05.197681Z","shell.execute_reply.started":"2023-02-27T09:24:05.187679Z"},"trusted":true},"outputs":[],"source":["input_ids, attention_mask = {'train': {0: [], 1:[]}, 'val': {0: [], 1:[]}}, {'train': {0: [], 1:[]}, 'val': {0: [], 1:[]}}"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-02-27T09:24:05.201161Z","iopub.status.busy":"2023-02-27T09:24:05.200343Z","iopub.status.idle":"2023-02-27T09:24:16.640786Z","shell.execute_reply":"2023-02-27T09:24:16.639496Z","shell.execute_reply.started":"2023-02-27T09:24:05.201124Z"},"trusted":true},"outputs":[],"source":["input_ids['train'][0], attention_mask['train'][0] = encode_input(list(train_df.sentence.values), model.tokenizer_1)\n","input_ids['train'][1], attention_mask['train'][1] = encode_input(list(train_df.sentence.values), model.tokenizer_2)\n","\n","print(input_ids['train'][0].shape, type(input_ids['train'][0]))\n","print(input_ids['train'][1].shape, type(input_ids['train'][1]))\n","print(attention_mask['train'][0].shape, type(attention_mask['train'][0]))\n","print(attention_mask['train'][1].shape, type(attention_mask['train'][1]))"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-02-27T09:24:16.642799Z","iopub.status.busy":"2023-02-27T09:24:16.642394Z","iopub.status.idle":"2023-02-27T09:24:17.620382Z","shell.execute_reply":"2023-02-27T09:24:17.619197Z","shell.execute_reply.started":"2023-02-27T09:24:16.642752Z"},"trusted":true},"outputs":[],"source":["input_ids['val'][0], attention_mask['val'][0] = encode_input(list(dev_df.sentence.values), model.tokenizer_1)\n","input_ids['val'][1], attention_mask['val'][1] = encode_input(list(dev_df.sentence.values), model.tokenizer_2)\n","\n","print(input_ids['val'][0].shape, type(input_ids['val'][0]))\n","print(input_ids['val'][1].shape, type(input_ids['val'][1]))\n","print(attention_mask['val'][0].shape, type(attention_mask['val'][0]))\n","print(attention_mask['val'][1].shape, type(attention_mask['val'][1]))"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-02-27T09:24:17.624174Z","iopub.status.busy":"2023-02-27T09:24:17.623462Z","iopub.status.idle":"2023-02-27T09:24:18.132662Z","shell.execute_reply":"2023-02-27T09:24:18.131292Z","shell.execute_reply.started":"2023-02-27T09:24:17.624132Z"},"trusted":true},"outputs":[],"source":["label_encode = {}\n","label_encode['train'] = th.LongTensor(train_labels)\n","label_encode['val'] = th.LongTensor(dev_labels)\n","\n","print(label_encode['train'].shape, type(label_encode['train']))\n","print(label_encode['val'].shape, type(label_encode['val']))"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-02-27T09:24:18.135535Z","iopub.status.busy":"2023-02-27T09:24:18.134692Z","iopub.status.idle":"2023-02-27T09:24:18.144239Z","shell.execute_reply":"2023-02-27T09:24:18.143171Z","shell.execute_reply.started":"2023-02-27T09:24:18.135494Z"},"trusted":true},"outputs":[],"source":["datasets = {}\n","loader = {}\n","for split in ['train', 'val']:\n","    \n","    datasets[split] =  Data.TensorDataset(input_ids[split][0], attention_mask[split][0], input_ids[split][1], attention_mask[split][1], label_encode[split])\n","    \n","    split_sampler = None\n","    if split == 'train':\n","        split_sampler = Data.RandomSampler(datasets[split])\n","    else:\n","        split_sampler = Data.SequentialSampler(datasets[split])\n","    \n","    loader[split] = Data.DataLoader(datasets[split], sampler = split_sampler, batch_size = batch_size)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-02-27T09:24:18.146722Z","iopub.status.busy":"2023-02-27T09:24:18.145948Z","iopub.status.idle":"2023-02-27T09:24:18.159519Z","shell.execute_reply":"2023-02-27T09:24:18.158312Z","shell.execute_reply.started":"2023-02-27T09:24:18.146683Z"},"trusted":true},"outputs":[],"source":["print(\"#train Dataset: \", len(datasets['train']))\n","print(\"#train Labels: \", len(label_encode['train']))\n","print(\"#train Loader: \", len(loader['train']))\n","\n","print(\"#dev Dataset: \", len(datasets['val']))\n","print(\"#dev Labels: \", len(label_encode['val']))\n","print(\"#dev Loader: \", len(loader['val']))"]},{"cell_type":"markdown","metadata":{},"source":["#### Optimizer and scheduler"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-02-27T09:24:18.162298Z","iopub.status.busy":"2023-02-27T09:24:18.161499Z","iopub.status.idle":"2023-02-27T09:24:18.171707Z","shell.execute_reply":"2023-02-27T09:24:18.170442Z","shell.execute_reply.started":"2023-02-27T09:24:18.162260Z"},"trusted":true},"outputs":[],"source":["optimizer = th.optim.Adam(model.parameters(), lr=1e-4)\n","scheduler = lr_scheduler.MultiStepLR(optimizer, milestones=[30], gamma=0.1)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{},"source":["#### Training"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-02-27T09:24:18.174277Z","iopub.status.busy":"2023-02-27T09:24:18.173506Z","iopub.status.idle":"2023-02-27T09:50:12.431373Z","shell.execute_reply":"2023-02-27T09:50:12.428561Z","shell.execute_reply.started":"2023-02-27T09:24:18.174240Z"},"trusted":true},"outputs":[],"source":["train_loss = []\n","val_loss = []\n","\n","train_acc = []\n","val_acc = []\n","\n","best_val_loss = None\n","\n","for epoch in range(epochs):\n","    print(\"Epoch: {}/{}\".format(epoch + 1 , epochs))\n","    \n","    t_loss, t_acc = 0, 0\n","    v_loss, v_acc = 0, 0\n","    \n","    actual_labels, predictions = [], []\n","    \n","    for step, batch in enumerate(loader['train']):\n","        \n","        # progress update after every 50 batches.\n","        print('\\rBatch {:>5,}  of  {:>5,}.'.format(step, len(loader['train'])), end='')\n","    \n","        model.train()\n","\n","        model = model.to(device)\n","        optimizer.zero_grad()\n","\n","        (input_ids_0, attention_mask_0, input_ids_1, attention_mask_1, label_0) = [x.to(device) for x in batch]\n","        optimizer.zero_grad()\n","\n","        y_pred = model([input_ids_0, attention_mask_0], [input_ids_1, attention_mask_1])\n","        y_true = label_0.type(th.long)\n","\n","        loss = F.cross_entropy(y_pred, y_true)\n","        loss.backward()\n","\n","        optimizer.step()\n","        t_loss += loss.item()\n","\n","        with th.no_grad():\n","            y_true = y_true.detach().cpu()\n","            y_pred = y_pred.argmax(axis=1).detach().cpu()\n","            t_acc += accuracy_score(y_true, y_pred)\n","            \n","            for i in y_true:\n","                actual_labels.append(i)\n","                \n","            for i in y_pred:\n","                predictions.append(i)\n","                \n","    train_loss.append(t_loss/len(loader['train']))\n","    train_acc.append(t_acc/len(loader['train']))\n","    f1_measure = f1_score(actual_labels, predictions, average='micro')\n","    \n","    print(\"Training Loss: \", t_loss/len(loader['train']))\n","    print(\"Train Accuracy: \", t_acc/len(loader['train']))\n","    print(\"F1 measure: \", f1_measure)\n","    \n","    #### Validating the validation samples\n","    predictions, actual_labels = [], []\n","    with th.no_grad():\n","        for step, batch in enumerate(loader['val']):\n","            \n","            # progress update after every 50 batches.\n","            print('\\rBatch {:>5,}  of  {:>5,}.'.format(step, len(loader['val'])), end=\"\")\n","                \n","            model.eval()\n","            model = model.to(device)\n","            \n","            (input_ids_0, attention_mask_0, input_ids_1, attention_mask_1, label_0) = [x.to(device) for x in batch]\n","            optimizer.zero_grad()\n","            \n","            y_pred = model([input_ids_0, attention_mask_0], [input_ids_1, attention_mask_1])\n","            y_true = label_0.type(th.long)\n","            \n","            loss = F.cross_entropy(y_pred, y_true)\n","            v_loss += loss.item()\n","            \n","            y_true = y_true.detach().cpu()\n","            y_pred = y_pred.argmax(axis=1).detach().cpu()\n","            \n","            for i in y_true:\n","                actual_labels.append(i)\n","                \n","            for i in y_pred:\n","                predictions.append(i)\n","                \n","            v_acc += accuracy_score(y_true, y_pred)\n","            \n","    val_loss.append(v_loss/len(loader['val']))\n","    val_acc.append(v_acc/len(loader['val']))\n","    \n","    f1_measure = f1_score(actual_labels, predictions, average='micro')\n","    \n","    print(\"Validation Loss: \", v_loss/len(loader['val']))\n","    print(\"Validation Accuracy: \", v_acc/len(loader['val']))\n","    print(\"Validation F1 measure: \", f1_measure)\n","    \n","    scheduler.step()\n","    \n","    if best_val_loss is None or best_val_loss > (v_acc/len(loader['val'])):\n","        th.save(\n","            {\n","                'bert_model_1': model.bert_model_1.state_dict(),\n","                'classifier_1': model.classifier_1.state_dict(),\n","                'bert_model_2': model.bert_model_2.state_dict(),\n","                'classifier_2': model.classifier_2.state_dict(),\n","                'classifier': model.classifier.state_dict(),\n","                'optimizer': optimizer.state_dict(),\n","                'epoch': epochs,\n","            },\n","            '../../checkpoints/checkpoint.pth'\n","        )\n","        best_val_loss = (v_acc/len(loader['val']))\n","        \n","        pred_labels = []\n","        for la in predictions:\n","            pred_labels.append(ID_Label_Map.get(str(la.item()), ''))\n","        df = pd.DataFrame(data = {'sentence': dev_sentences, 'actual': dev_actual_labels, 'predict': pred_labels}, columns = ['sentence', 'actual', 'predict'])\n","        df.to_csv('../../model_results/eval_predictions.csv')"]},{"cell_type":"markdown","metadata":{},"source":["### Accuracy and Loss plots"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2023-02-27T09:50:12.434349Z","iopub.status.idle":"2023-02-27T09:50:12.436634Z","shell.execute_reply":"2023-02-27T09:50:12.436410Z","shell.execute_reply.started":"2023-02-27T09:50:12.436383Z"},"trusted":true},"outputs":[],"source":["fig, (ax1, ax2) = plt.subplots(figsize = (8, 4), nrows = 1, ncols=2)\n","\n","ax1.plot(range(epochs), train_loss, label='train', color='red')\n","ax1.scatter(range(epochs), train_loss, color='red')\n","ax1.plot(range(epochs), val_loss, label='dev', color='blue')\n","ax1.scatter(range(epochs), val_loss, color='blue')\n","ax1.set(xlabel = 'Epochs', ylabel = 'Loss')\n","ax1.set_title('Train vs Dev Loss')\n","ax1.legend()\n","\n","ax2.plot(range(epochs), train_acc, label='train', color='red')\n","ax2.scatter(range(epochs), train_loss, color='red')\n","ax2.plot(range(epochs), val_acc, label='dev', color='blue')\n","ax2.scatter(range(epochs), val_acc, color='blue')\n","ax2.set(xlabel = 'Epochs', ylabel = 'Accuracy')\n","ax2.set_title('Train vs Dev Accuracy')\n","ax2.legend()\n","\n","fig.savefig('train_vs_test_loss_and_accuracy.jpg')\n","fig.show()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{},"source":["## Test Data Inference and submission file preparation"]},{"cell_type":"markdown","metadata":{},"source":["### Load the labels list"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["print(ID_Label_Map)\n","labels_list = []\n","for i in range(len(ID_Label_Map)):\n","    label = ID_Label_Map[str(i)]\n","    labels_list.append(label)\n","\n","print(labels_list)"]},{"cell_type":"markdown","metadata":{},"source":["### Read testset"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["rr_test_data = {}\n","with open('../../data/model_data/SAMPLE_SUBMISSION_RR.json', 'r') as fp:\n","    rr_test_data = json.load(fp)\n","print(\"# Documents: \", len(rr_test_data))"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["final_results = rr_test_data.copy()\n","for doc_index, entry in tqdm(enumerate(rr_test_data)):\n","    results = rr_test_data[doc_index]['annotations'][0]['result']\n","    for sent_index, sent in enumerate(results):\n","        \n","        #### Extracting the text from the test data\n","        sentence = sent['value']['text']\n","        sentence = sentence.replace(r'\\s+', ' ').strip()\n","        \n","        #### Getting input ids and attention mask from the model for the given sentence\n","        input_ids_1, attention_mask_1 = encode_input([sentence], model.tokenizer_1)\n","        input_ids_2, attention_mask_2 = encode_input([sentence], model.tokenizer_2)\n","\n","        label = None\n","        with torch.no_grad():\n","            model.eval()\n","            model.to(device)\n","            y_pred = model([input_ids_1.to(device), input_ids_2.to(device)], [attention_mask_1.to(device), attention_mask_2.to(device)]).cpu()\n","            label = labels_list[np.argmax(y_pred)]\n","        \n","        if label is not None:\n","            final_results[doc_index]['annotations'][0]['result'][sent_index]['value']['labels'] = [label]\n","        else:\n","            print(\"Label is None for Doc-index: {} and Sent-index: {}\".format(doc_index, sent_index))\n","\n","print(\"# Documents: \", len(final_results))"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["with open('../../output/RR_SUBMISSION.json', 'w') as fp:\n","    json.dump(final_results, fp, indent=4)"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.4"}},"nbformat":4,"nbformat_minor":4}
