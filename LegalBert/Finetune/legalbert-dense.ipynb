{"cells":[{"cell_type":"markdown","metadata":{},"source":["## Installing necessary packages"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-02-27T05:51:00.804271Z","iopub.status.busy":"2023-02-27T05:51:00.803439Z","iopub.status.idle":"2023-02-27T05:51:10.517149Z","shell.execute_reply":"2023-02-27T05:51:10.515942Z","shell.execute_reply.started":"2023-02-27T05:51:00.804227Z"},"trusted":true},"outputs":[],"source":["!pip install transformers --q"]},{"cell_type":"markdown","metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5"},"source":["## Importing necessary packages"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-02-27T06:18:49.856818Z","iopub.status.busy":"2023-02-27T06:18:49.856057Z","iopub.status.idle":"2023-02-27T06:18:49.867693Z","shell.execute_reply":"2023-02-27T06:18:49.866608Z","shell.execute_reply.started":"2023-02-27T06:18:49.856779Z"},"trusted":true},"outputs":[],"source":["import pandas as pd\n","import numpy as np\n","from numpy import zeros\n","\n","from tqdm import tqdm\n","\n","import json\n","import torch\n","\n","from transformers import AutoModel, AutoTokenizer\n","from sklearn.preprocessing import LabelEncoder\n","from sklearn.metrics import accuracy_score, f1_score\n","\n","\n","import torch as th\n","from transformers import AutoModel, AutoTokenizer\n","import torch.utils.data as Data\n","from torch.optim import lr_scheduler\n","import torch.nn.functional as F\n","\n","import matplotlib.pyplot as plt\n","%matplotlib inline"]},{"cell_type":"markdown","metadata":{},"source":["## Parameters"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-02-27T05:51:15.516669Z","iopub.status.busy":"2023-02-27T05:51:15.515900Z","iopub.status.idle":"2023-02-27T05:51:15.523519Z","shell.execute_reply":"2023-02-27T05:51:15.520672Z","shell.execute_reply.started":"2023-02-27T05:51:15.516636Z"},"trusted":true},"outputs":[],"source":["sequence_length = 256\n","embedding_dim = 768\n","batch_size = 32\n","epochs = 6\n","model_name = 'nlpaueb/legal-bert-base-uncased'\n","output_type = 'mean_pooled' # by default CLS"]},{"cell_type":"markdown","metadata":{},"source":["## Dataset Loader"]},{"cell_type":"markdown","metadata":{},"source":["#### Training dataset"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-02-27T05:51:15.528645Z","iopub.status.busy":"2023-02-27T05:51:15.527746Z","iopub.status.idle":"2023-02-27T05:51:15.613182Z","shell.execute_reply":"2023-02-27T05:51:15.612029Z","shell.execute_reply.started":"2023-02-27T05:51:15.528591Z"},"trusted":true},"outputs":[],"source":["train_df = pd.read_csv('../../data/model_data/train_df.csv')\n","print(\"# Size: \", train_df.shape)\n","train_df.head()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-02-27T05:51:15.616000Z","iopub.status.busy":"2023-02-27T05:51:15.614886Z","iopub.status.idle":"2023-02-27T05:51:15.626302Z","shell.execute_reply":"2023-02-27T05:51:15.625156Z","shell.execute_reply.started":"2023-02-27T05:51:15.615959Z"},"trusted":true},"outputs":[],"source":["print(\"#Nan in sents: \", train_df.sentence.isnull().values.sum())\n","print(\"#Nan in labels: \", train_df.label.isnull().values.sum())"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-02-27T05:51:15.628415Z","iopub.status.busy":"2023-02-27T05:51:15.627902Z","iopub.status.idle":"2023-02-27T05:51:15.641070Z","shell.execute_reply":"2023-02-27T05:51:15.639843Z","shell.execute_reply.started":"2023-02-27T05:51:15.628360Z"},"trusted":true},"outputs":[],"source":["train_df.label.value_counts()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{},"source":["#### Validation dataset"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-02-27T05:51:15.643349Z","iopub.status.busy":"2023-02-27T05:51:15.642976Z","iopub.status.idle":"2023-02-27T05:51:15.667008Z","shell.execute_reply":"2023-02-27T05:51:15.666042Z","shell.execute_reply.started":"2023-02-27T05:51:15.643314Z"},"trusted":true},"outputs":[],"source":["dev_df = pd.read_csv('../../data/model_data/dev_df.csv')\n","print(\"# Size: \", dev_df.shape)\n","dev_df.head()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-02-27T05:51:15.668926Z","iopub.status.busy":"2023-02-27T05:51:15.668412Z","iopub.status.idle":"2023-02-27T05:51:15.679160Z","shell.execute_reply":"2023-02-27T05:51:15.678031Z","shell.execute_reply.started":"2023-02-27T05:51:15.668875Z"},"trusted":true},"outputs":[],"source":["print(\"#Nan in sents: \", dev_df.sentence.isnull().values.sum())\n","print(\"#Nan in labels: \", dev_df.label.isnull().values.sum())"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-02-27T05:51:15.681558Z","iopub.status.busy":"2023-02-27T05:51:15.680605Z","iopub.status.idle":"2023-02-27T05:51:15.692754Z","shell.execute_reply":"2023-02-27T05:51:15.691757Z","shell.execute_reply.started":"2023-02-27T05:51:15.681521Z"},"trusted":true},"outputs":[],"source":["dev_df.label.value_counts()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{},"source":["#### Reading labels"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-02-27T05:51:15.694846Z","iopub.status.busy":"2023-02-27T05:51:15.694295Z","iopub.status.idle":"2023-02-27T05:51:15.715488Z","shell.execute_reply":"2023-02-27T05:51:15.714026Z","shell.execute_reply.started":"2023-02-27T05:51:15.694691Z"},"trusted":true},"outputs":[],"source":["le_encoder = LabelEncoder()\n","le_encoder.fit(list(train_df.label.values) + list(dev_df.label.values))\n","\n","label_names = le_encoder.classes_\n","print(label_names)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-02-27T05:51:15.717602Z","iopub.status.busy":"2023-02-27T05:51:15.717235Z","iopub.status.idle":"2023-02-27T05:51:15.725929Z","shell.execute_reply":"2023-02-27T05:51:15.724736Z","shell.execute_reply.started":"2023-02-27T05:51:15.717566Z"},"trusted":true},"outputs":[],"source":["ID_Label_Map = {}\n","with open('../../data/model_data/ID_Label_Map.json', 'r') as fp:\n","    ID_Label_Map = json.load(fp)\n","\n","Label_ID_Map = {}\n","with open('../../data/model_data/Label_ID_Map.json', 'r') as fp:\n","    Label_ID_Map = json.load(fp)\n","\n","print(list(Label_ID_Map.keys()))"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-02-27T05:51:15.728309Z","iopub.status.busy":"2023-02-27T05:51:15.727883Z","iopub.status.idle":"2023-02-27T05:51:15.754060Z","shell.execute_reply":"2023-02-27T05:51:15.753130Z","shell.execute_reply.started":"2023-02-27T05:51:15.728270Z"},"trusted":true},"outputs":[],"source":["train_labels = le_encoder.transform(list(train_df.label.values))\n","print(\"# Labels: \", len(train_labels))"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-02-27T05:51:15.758700Z","iopub.status.busy":"2023-02-27T05:51:15.758414Z","iopub.status.idle":"2023-02-27T05:51:15.765992Z","shell.execute_reply":"2023-02-27T05:51:15.764925Z","shell.execute_reply.started":"2023-02-27T05:51:15.758674Z"},"trusted":true},"outputs":[],"source":["dev_labels = le_encoder.transform(list(dev_df.label.values))\n","print(\"# Labels: \", len(dev_labels))"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{},"source":["## Bert Model"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["class DenseLayer(th.nn.Module):\n","    def __init__(self, bert_hidden_size, num_labels):\n","        super(DenseLayer, self).__init__()\n","        self.linear1 = th.nn.Linear(bert_hidden_size, 512)\n","        self.linear2 = th.nn.Linear(512, 256)\n","        self.linear3 = th.nn.Linear(256, num_labels)\n","        self.dropout = th.nn.Dropout(0.1)\n","        self.relu = th.nn.ReLU()\n","        \n","    def forward(self, x):\n","        x = self.linear1(x)\n","        x = self.dropout(x)\n","        x = self.relu(x)\n","        x = self.linear2(x)\n","        x = self.dropout(x)\n","        x = self.relu(x)\n","        x = self.linear3(x)\n","        return x"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-02-27T05:51:15.768152Z","iopub.status.busy":"2023-02-27T05:51:15.767445Z","iopub.status.idle":"2023-02-27T05:51:15.776856Z","shell.execute_reply":"2023-02-27T05:51:15.775897Z","shell.execute_reply.started":"2023-02-27T05:51:15.768078Z"},"trusted":true},"outputs":[],"source":["class BertClassifier(th.nn.Module):\n","    def __init__(self, pretrained_model='roberta-base', nb_class=20):\n","        super(BertClassifier, self).__init__()\n","        self.nb_class = nb_class\n","        self.tokenizer = AutoTokenizer.from_pretrained(pretrained_model)\n","        self.bert_model = AutoModel.from_pretrained(pretrained_model)\n","        self.feat_dim = list(self.bert_model.modules())[-2].out_features\n","        self.classifier = DenseLayer(self.feat_dim, nb_class)\n","\n","    def forward(self, input_ids, attention_mask, output_type = 'CLS'):\n","\n","        cls_feats = None\n","        if output_type=='mean_pooled':\n","            bert_output = self.bert_model(input_ids, attention_mask).last_hidden_state\n","            \n","            ### Mean Pooling\n","            cls_feats = bert_output.sum(axis=1) / attention_mask.sum(axis=-1).unsqueeze(-1)\n","        else:\n","            cls_feats = self.bert_model(input_ids, attention_mask)[0][:, 0]\n","        \n","        logits = self.classifier(cls_feats)\n","        \n","        return logits"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-02-27T05:51:15.779020Z","iopub.status.busy":"2023-02-27T05:51:15.778210Z","iopub.status.idle":"2023-02-27T05:51:21.235853Z","shell.execute_reply":"2023-02-27T05:51:21.234668Z","shell.execute_reply.started":"2023-02-27T05:51:15.778984Z"},"trusted":true},"outputs":[],"source":["model = BertClassifier(pretrained_model = model_name, nb_class=len(ID_Label_Map))"]},{"cell_type":"markdown","metadata":{},"source":["#### Preparing the data loader for bert classifier"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-02-27T05:51:21.238570Z","iopub.status.busy":"2023-02-27T05:51:21.238073Z","iopub.status.idle":"2023-02-27T05:51:21.277116Z","shell.execute_reply":"2023-02-27T05:51:21.274912Z","shell.execute_reply.started":"2023-02-27T05:51:21.238522Z"},"trusted":true},"outputs":[],"source":["device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-02-27T05:51:21.279239Z","iopub.status.busy":"2023-02-27T05:51:21.278707Z","iopub.status.idle":"2023-02-27T05:51:21.288514Z","shell.execute_reply":"2023-02-27T05:51:21.287555Z","shell.execute_reply.started":"2023-02-27T05:51:21.279192Z"},"trusted":true},"outputs":[],"source":["def encode_input(text, tokenizer):\n","    tokenized_text = tokenizer(\n","        text,\n","        max_length = sequence_length,\n","        padding='max_length',\n","        truncation=True,\n","        return_tensors='pt'\n","    )\n","    return tokenized_text.input_ids, tokenized_text.attention_mask"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-02-27T05:51:21.291185Z","iopub.status.busy":"2023-02-27T05:51:21.290324Z","iopub.status.idle":"2023-02-27T05:51:21.299922Z","shell.execute_reply":"2023-02-27T05:51:21.298997Z","shell.execute_reply.started":"2023-02-27T05:51:21.291145Z"},"trusted":true},"outputs":[],"source":["input_ids, attention_mask = {}, {}"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-02-27T05:51:21.303836Z","iopub.status.busy":"2023-02-27T05:51:21.303518Z","iopub.status.idle":"2023-02-27T05:51:27.745298Z","shell.execute_reply":"2023-02-27T05:51:27.744166Z","shell.execute_reply.started":"2023-02-27T05:51:21.303807Z"},"trusted":true},"outputs":[],"source":["input_ids['train'], attention_mask['train'] = encode_input(list(train_df.sentence.values), model.tokenizer)\n","\n","print(input_ids['train'].shape, type(input_ids['train']))\n","print(attention_mask['train'].shape, type(attention_mask['train']))"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-02-27T05:51:27.747584Z","iopub.status.busy":"2023-02-27T05:51:27.746882Z","iopub.status.idle":"2023-02-27T05:51:27.753592Z","shell.execute_reply":"2023-02-27T05:51:27.752405Z","shell.execute_reply.started":"2023-02-27T05:51:27.747526Z"},"trusted":true},"outputs":[],"source":["dev_sentences = list(dev_df.sentence.values)\n","dev_actual_labels = list(dev_df.label.values)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-02-27T05:51:27.757143Z","iopub.status.busy":"2023-02-27T05:51:27.756112Z","iopub.status.idle":"2023-02-27T05:51:28.245126Z","shell.execute_reply":"2023-02-27T05:51:28.242910Z","shell.execute_reply.started":"2023-02-27T05:51:27.757103Z"},"trusted":true},"outputs":[],"source":["input_ids['val'], attention_mask['val'] = encode_input(dev_sentences, model.tokenizer)\n","\n","print(input_ids['val'].shape, type(input_ids['val']))\n","print(attention_mask['val'].shape, type(attention_mask['val']))"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-02-27T05:51:28.246830Z","iopub.status.busy":"2023-02-27T05:51:28.246446Z","iopub.status.idle":"2023-02-27T05:51:28.253514Z","shell.execute_reply":"2023-02-27T05:51:28.252478Z","shell.execute_reply.started":"2023-02-27T05:51:28.246788Z"},"trusted":true},"outputs":[],"source":["label_encode = {}\n","label_encode['train'] = th.LongTensor(train_labels)\n","label_encode['val'] = th.LongTensor(dev_labels)\n","\n","print(label_encode['train'].shape, type(label_encode['train']))\n","print(label_encode['val'].shape, type(label_encode['val']))"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-02-27T05:51:28.255839Z","iopub.status.busy":"2023-02-27T05:51:28.255036Z","iopub.status.idle":"2023-02-27T05:51:28.266496Z","shell.execute_reply":"2023-02-27T05:51:28.265327Z","shell.execute_reply.started":"2023-02-27T05:51:28.255802Z"},"trusted":true},"outputs":[],"source":["datasets = {}\n","loader = {}\n","for split in ['train', 'val']:\n","    datasets[split] =  Data.TensorDataset(input_ids[split], attention_mask[split], label_encode[split])\n","    split_sampler = None\n","    if split == 'train':\n","        split_sampler = Data.RandomSampler(datasets[split])\n","    else:\n","        split_sampler = Data.SequentialSampler(datasets[split])  \n","    loader[split] = Data.DataLoader(datasets[split], sampler = split_sampler, batch_size = batch_size)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-02-27T05:51:28.268564Z","iopub.status.busy":"2023-02-27T05:51:28.268145Z","iopub.status.idle":"2023-02-27T05:51:28.278613Z","shell.execute_reply":"2023-02-27T05:51:28.277515Z","shell.execute_reply.started":"2023-02-27T05:51:28.268526Z"},"trusted":true},"outputs":[],"source":["print(\"#train Dataset: \", len(datasets['train']))\n","print(\"#train Labels: \", len(label_encode['train']))\n","print(\"#train Loader: \", len(loader['train']))\n","\n","print(\"#dev Dataset: \", len(datasets['val']))\n","print(\"#dev Labels: \", len(label_encode['val']))\n","print(\"#dev Loader: \", len(loader['val']))"]},{"cell_type":"markdown","metadata":{},"source":["#### Optimizer and scheduler"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-02-27T05:51:28.280634Z","iopub.status.busy":"2023-02-27T05:51:28.280189Z","iopub.status.idle":"2023-02-27T05:51:28.288696Z","shell.execute_reply":"2023-02-27T05:51:28.287728Z","shell.execute_reply.started":"2023-02-27T05:51:28.280596Z"},"trusted":true},"outputs":[],"source":["optimizer = th.optim.Adam(model.parameters(), lr=1e-4)\n","scheduler = lr_scheduler.MultiStepLR(optimizer, milestones=[30], gamma=0.1)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{},"source":["#### Training"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-02-27T05:51:28.290817Z","iopub.status.busy":"2023-02-27T05:51:28.290447Z","iopub.status.idle":"2023-02-27T06:14:46.070160Z","shell.execute_reply":"2023-02-27T06:14:46.069010Z","shell.execute_reply.started":"2023-02-27T05:51:28.290780Z"},"trusted":true},"outputs":[],"source":["train_loss = []\n","val_loss = []\n","\n","train_acc = []\n","val_acc = []\n","\n","best_val_loss = None\n","\n","for epoch in range(epochs):\n","    print(\"Epoch: {}/{}\".format(epoch + 1 , epochs))\n","    \n","    t_loss, t_acc = 0, 0\n","    v_loss, v_acc = 0, 0\n","    \n","    actual_labels, predictions = [], []\n","    \n","    for step, batch in enumerate(loader['train']):\n","        \n","        # progress update after every 50 batches.\n","        print('\\rBatch {:>5,}  of  {:>5,}.'.format(step, len(loader['train'])), end='')\n","    \n","        model.train()\n","\n","        model = model.to(device)\n","        optimizer.zero_grad()\n","\n","        (input_ids, attention_mask, label) = [x.to(device) for x in batch]\n","        optimizer.zero_grad()\n","\n","        y_pred = model(input_ids, attention_mask)\n","        y_true = label.type(th.long)\n","\n","        loss = F.cross_entropy(y_pred, y_true)\n","        loss.backward()\n","\n","        optimizer.step()\n","        t_loss += loss.item()\n","\n","        with th.no_grad():\n","            y_true = y_true.detach().cpu()\n","            y_pred = y_pred.argmax(axis=1).detach().cpu()\n","            t_acc += accuracy_score(y_true, y_pred)\n","            \n","            for i in y_true:\n","                actual_labels.append(i)\n","                \n","            for i in y_pred:\n","                predictions.append(i)\n","                \n","    train_loss.append(t_loss/len(loader['train']))\n","    train_acc.append(t_acc/len(loader['train']))\n","    f1_measure = f1_score(actual_labels, predictions, average='micro')\n","    \n","    print(\"Training Loss: \", t_loss/len(loader['train']))\n","    print(\"Train Accuracy: \", t_acc/len(loader['train']))\n","    print(\"F1 measure: \", f1_measure)\n","    \n","    #### Validating the validation samples\n","    predictions, actual_labels = [], []\n","    with th.no_grad():\n","        for step, batch in enumerate(loader['val']):\n","            \n","            # progress update after every 50 batches.\n","            print('\\rBatch {:>5,}  of  {:>5,}.'.format(step, len(loader['val'])), end=\"\")\n","                \n","            model.eval()\n","            model = model.to(device)\n","            \n","            (input_ids, attention_mask, label) = [x.to(device) for x in batch]\n","            optimizer.zero_grad()\n","            \n","            y_pred = model(input_ids, attention_mask)\n","            y_true = label.type(th.long)\n","            \n","            loss = F.cross_entropy(y_pred, y_true)\n","            v_loss += loss.item()\n","            \n","            y_true = y_true.detach().cpu()\n","            y_pred = y_pred.argmax(axis=1).detach().cpu()\n","            \n","            for i in y_true:\n","                actual_labels.append(i)\n","                \n","            for i in y_pred:\n","                predictions.append(i)\n","                \n","            v_acc += accuracy_score(y_true, y_pred)\n","            \n","    val_loss.append(v_loss/len(loader['val']))\n","    val_acc.append(v_acc/len(loader['val']))\n","    \n","    f1_measure = f1_score(actual_labels, predictions, average='micro')\n","    \n","    print(\"Validation Loss: \", v_loss/len(loader['val']))\n","    print(\"Validation Accuracy: \", v_acc/len(loader['val']))\n","    print(\"Validation F1 measure: \", f1_measure)\n","    \n","    scheduler.step()\n","    \n","    if best_val_loss is None or best_val_loss > (v_acc/len(loader['val'])):\n","        th.save(\n","            {\n","                'bert_model': model.bert_model.state_dict(),\n","                'classifier': model.classifier.state_dict(),\n","                'optimizer': optimizer.state_dict(),\n","                'epoch': epochs,\n","            },\n","            '../../checkpoints/checkpoint.pth'\n","        )\n","        best_val_loss = (v_acc/len(loader['val']))\n","        \n","        pred_labels = []\n","        for la in predictions:\n","            pred_labels.append(ID_Label_Map.get(str(la.item()), ''))\n","        df = pd.DataFrame(data = {'sentence': dev_sentences, 'actual': dev_actual_labels, 'predict': pred_labels}, columns = ['sentence', 'actual', 'predict'])\n","        df.to_csv('../../model_results/eval_predictions.csv')"]},{"cell_type":"markdown","metadata":{},"source":["### Accuracy and Loss plots"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-02-27T06:21:26.309370Z","iopub.status.busy":"2023-02-27T06:21:26.308413Z","iopub.status.idle":"2023-02-27T06:21:27.066795Z","shell.execute_reply":"2023-02-27T06:21:27.065631Z","shell.execute_reply.started":"2023-02-27T06:21:26.309317Z"},"trusted":true},"outputs":[],"source":["fig, (ax1, ax2) = plt.subplots(figsize = (8, 4), nrows = 1, ncols=2)\n","\n","ax1.plot(range(epochs), train_loss, label='train', color='red')\n","ax1.scatter(range(epochs), train_loss, color='red')\n","ax1.plot(range(epochs), val_loss, label='dev', color='blue')\n","ax1.scatter(range(epochs), val_loss, color='blue')\n","ax1.set(xlabel = 'Epochs', ylabel = 'Loss')\n","ax1.set_title('Train vs Dev Loss')\n","ax1.legend()\n","\n","ax2.plot(range(epochs), train_acc, label='train', color='red')\n","ax2.scatter(range(epochs), train_loss, color='red')\n","ax2.plot(range(epochs), val_acc, label='dev', color='blue')\n","ax2.scatter(range(epochs), val_acc, color='blue')\n","ax2.set(xlabel = 'Epochs', ylabel = 'Accuracy')\n","ax2.set_title('Train vs Dev Accuracy')\n","ax2.legend()\n","\n","fig.savefig('train_vs_test_loss_and_accuracy.jpg')\n","fig.show()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## Test Data Inference and submission file preparation"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["### Load best model"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["model = BertClassifier(pretrained_model='../../checkpoints/checkpoint.pth', nb_class=len(Label_ID_Map))"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["### Load the labels list"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["print(ID_Label_Map)\n","labels_list = []\n","for i in range(len(ID_Label_Map)):\n","    label = ID_Label_Map[str(i)]\n","    labels_list.append(label)\n","\n","print(labels_list)"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["### Predictions for the testset"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["rr_test_data = {}\n","with open('../../data/model_data/SAMPLE_SUBMISSION_RR.json', 'r') as fp:\n","    rr_test_data = json.load(fp)\n","print(\"# Documents: \", len(rr_test_data))"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["final_results = rr_test_data.copy()\n","for doc_index, entry in tqdm(enumerate(rr_test_data)):\n","    results = rr_test_data[doc_index]['annotations'][0]['result']\n","    for sent_index, sent in enumerate(results):\n","        \n","        #### Extracting the text from the test data\n","        sentence = sent['value']['text']\n","        sentence = sentence.replace(r'\\s+', ' ').strip()\n","        \n","        #### Getting input ids and attention mask from the model for the given sentence\n","        input_ids, attention_mask = encode_input([sentence], model.tokenizer)\n","        \n","        label = None\n","        #### Predicting the label index from the model\n","        with th.no_grad():\n","            model.eval()\n","            model.to(device)\n","            y_pred = model(input_ids.to(device), attention_mask.to(device)).cpu()\n","            label = labels_list[np.argmax(y_pred)]\n","        \n","        if label is not None:\n","            final_results[doc_index]['annotations'][0]['result'][sent_index]['value']['labels'] = [label]\n","        else:\n","            print(\"Label is None for Doc-index: {} and Sent-index: {}\".format(doc_index, sent_index))\n","\n","print(\"# Documents: \", len(final_results))"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["with open('../../output/RR_SUBMISSION.json', 'w') as fp:\n","    json.dump(final_results, fp, indent=4)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.4"}},"nbformat":4,"nbformat_minor":4}
